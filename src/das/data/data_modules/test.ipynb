{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 01:15:27 port-41xx das.data.data_modules.base[125294] INFO Preparing / preprocesing dataset and saving to cache...\n",
      "2021-11-22 01:15:27 port-41xx das.data.data_modules.base[125294] INFO Training stage == None\n",
      "2021-11-22 01:15:27 port-41xx das.data.data_modules.base[125294] INFO Setting up train/validation dataset...\n",
      "2021-11-22 01:15:27 port-41xx das.data.datasets.data_cacher[125294] INFO Loading dataset [tobacco3842-train] from cached file: //netscratch/saifullah/document_analysis_stack/datasets/tobacco3842/train/datadings_orig.df\n",
      "2021-11-22 01:15:27 port-41xx das.data.datasets.datasets_base[125294] INFO Defining data transformations [train]:\n",
      "2021-11-22 01:15:27 port-41xx das.data.data_modules.base[125294] INFO Training set size = 2226\n",
      "2021-11-22 01:15:27 port-41xx das.data.data_modules.base[125294] INFO Validation set size = 556\n",
      "2021-11-22 01:15:27 port-41xx das.data.datasets.data_cacher[125294] INFO Loading dataset [tobacco3842-test] from cached file: //netscratch/saifullah/document_analysis_stack/datasets/tobacco3842/test/datadings_orig.df\n",
      "2021-11-22 01:15:27 port-41xx das.data.datasets.datasets_base[125294] INFO Defining data transformations [test]:\n",
      "2021-11-22 01:15:27 port-41xx das.data.data_modules.base[125294] INFO Test set size = 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t GrayScaleToRGB()\n",
      "\t Rescale()\n",
      "\t ConvertImageDtype()\n",
      "\t Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "\t GrayScaleToRGB()\n",
      "\t Rescale()\n",
      "\t ConvertImageDtype()\n",
      "\t Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n"
     ]
    }
   ],
   "source": [
    "from das.utils.basic_args import BasicArguments\n",
    "from das.data.data_args import DataArguments\n",
    "from das.data.data_modules.factory import DataModuleFactory\n",
    "from das.utils.arg_parser import DASArgumentParser\n",
    "import torch\n",
    "\n",
    "# class DataCollatorForTextClassification:\n",
    "#     \"\"\"\n",
    "#     Data collator for text classification using feed forward language modeling.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __call__(self, batch):\n",
    "#         label_list, input_ids_list, offsets = [], [], [0]\n",
    "#         for sample in batch:\n",
    "#             label_list.append(sample['labels'])\n",
    "#             input_ids = torch.tensor(sample['input_ids'], dtype=torch.int64)\n",
    "#             input_ids_list.append(input_ids)\n",
    "#             offsets.append(input_ids.size(0))\n",
    "#         label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "#         offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "#         input_ids_list = torch.cat(input_ids_list)\n",
    "\n",
    "#         return {\n",
    "#             'input_ids': input_ids_list,\n",
    "#             'target_labels': label_list,\n",
    "#             'offsets': offsets\n",
    "#         }\n",
    "\n",
    "\n",
    "def parse_cfg(cfg, args):\n",
    "    \"\"\"\n",
    "    Parses script arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the argument parsers\n",
    "    arg_parser = DASArgumentParser(args)\n",
    "\n",
    "    # parse arguments either based on a json file or directly\n",
    "    if cfg.endswith(\".yaml\"):\n",
    "        return arg_parser.parse_yaml_file(os.path.abspath(cfg))\n",
    "\n",
    "basic_args = list(parse_cfg('/home/saifullah/work/document_analysis_stack/cfg/basic_args.yaml', [BasicArguments]))[0]\n",
    "data_args = list(parse_cfg('/home/saifullah/work/document_analysis_stack/cfg/datasets/tobacco3842.yaml', [DataArguments]))[0]\n",
    "data_args.data_caching_args.use_datadings = False\n",
    "datamodule = DataModuleFactory.create_datamodule(basic_args, data_args)\n",
    "\n",
    "# prepare data for usage later on model\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tData:\n",
      "torch.Size([256, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dl = datamodule.train_dataloader()\n",
    "for data in datamodule.train_dataloader():\n",
    "    print(f\"\\t\\t\\tData:\\n{data['image'].shape}\")\n",
    "    break\n",
    "\n",
    "# dl = datamodule.val_dataloader()\n",
    "# for data in datamodule.val_dataloader():\n",
    "#     print(f\"\\t\\t\\tData:\\n{data}\")\n",
    "#     break\n",
    "\n",
    "# dl = datamodule.test_dataloader()\n",
    "# for data in datamodule.test_dataloader():\n",
    "\n",
    "#     print(f\"\\t\\t\\tData:\\n{data}\")\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc3803ff4c70635b3705e3d6b639c0de7f0fe170b9184eb396efc73b74d73b8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('nlp': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
